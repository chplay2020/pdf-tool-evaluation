# LightRAG PDF Preprocessing Pipeline

Pipeline tiá»n xá»­ lÃ½ PDF cho LightRAG - chuyá»ƒn Ä‘á»•i PDF Ä‘a lÄ©nh vá»±c (Y há»c, CNTT, Kinh táº¿, Luáº­t, ...) thÃ nh semantic nodes vá»›i auto-tagging.

## ğŸ“‹ Tá»•ng quan

Pipeline nÃ y chuyá»ƒn Ä‘á»•i file PDF thÃ nh cÃ¡c semantic nodes tÆ°Æ¡ng thÃ­ch vá»›i LightRAG, bao gá»“m:
- âœ… Chuyá»ƒn Ä‘á»•i PDF â†’ Markdown (Marker)
- âœ… LÃ m sáº¡ch ná»™i dung (loáº¡i header/footer, normalize whitespace)
- âœ… Sá»­a lá»—i tiáº¿ng Viá»‡t (line-break, OCR errors)
- âœ… Táº¡o semantic nodes (150-400 tokens)
- âœ… Deduplication vÃ  quality assurance
- âœ… **Auto-tagging Ä‘a lÄ©nh vá»±c** (Y há»c, CNTT, Kinh táº¿, Luáº­t, ...)
- âœ… **Export text files** Ä‘á»ƒ review trÆ°á»›c khi train AI

## ğŸ—ï¸ Cáº¥u trÃºc Project

```
pdf-tool-evaluation/
â”œâ”€â”€ README.md                      # File nÃ y
â”œâ”€â”€ .gitignore
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ main_pipeline.py           # Script chÃ­nh - cháº¡y toÃ n bá»™ pipeline
    â”œâ”€â”€ marker.py                  # Module chuyá»ƒn Ä‘á»•i PDF â†’ Markdown
    â”œâ”€â”€ export_text.py             # Export JSON â†’ Text files
    â”œâ”€â”€ requirements.txt           # Dependencies
    â”‚
    â”œâ”€â”€ pipeline/                  # CÃ¡c module xá»­ lÃ½
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ cleaning_v1.py         # BÆ°á»›c 1: LÃ m sáº¡ch markdown
    â”‚   â”œâ”€â”€ final_cleaning.py      # BÆ°á»›c 2: Sá»­a lá»—i tiáº¿ng Viá»‡t
    â”‚   â”œâ”€â”€ chunking.py            # BÆ°á»›c 3: Táº¡o semantic nodes
    â”‚   â”œâ”€â”€ audit_nodes.py         # BÆ°á»›c 4: Deduplication & QA
    â”‚   â””â”€â”€ auto_tagging.py        # BÆ°á»›c 5: Auto-tagging Ä‘a lÄ©nh vá»±c
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ raw/                   # Input: File PDF
    â”‚   â”œâ”€â”€ processed/             # Output: File JSON cho LightRAG
    â”‚   â””â”€â”€ exported/              # Output: File text Ä‘á»ƒ review
    â”‚
    â”œâ”€â”€ temp_pipeline/             # (Optional) Káº¿t quáº£ intermediate
    â””â”€â”€ venv_marker/               # Virtual environment
```

## ğŸš€ HÆ°á»›ng dáº«n CÃ i Ä‘áº·t

### 1. Clone Repository

```bash
git clone <repository-url>
cd pdf-tool-evaluation/src
```

### 2. Táº¡o Virtual Environment

```bash
# Táº¡o virtual environment
python3 -m venv venv_marker

# KÃ­ch hoáº¡t (Linux/Mac)
source venv_marker/bin/activate

# KÃ­ch hoáº¡t (Windows)
venv_marker\Scripts\activate
```

### 3. CÃ i Ä‘áº·t Dependencies

```bash
pip install -r requirements.txt
```

**LÆ°u Ã½:** Marker sáº½ tá»± Ä‘á»™ng download models (~2-3GB) khi cháº¡y láº§n Ä‘áº§u.

## ğŸ“ CÃ¡ch Sá»­ dá»¥ng

### BÆ°á»›c 1: Chuáº©n bá»‹ File PDF

Äáº·t file PDF vÃ o thÆ° má»¥c `data/raw/`:

```bash
cp /path/to/your/document.pdf data/raw/
```

### BÆ°á»›c 2: Xem Danh sÃ¡ch PDF

```bash
python main_pipeline.py --list
```

### BÆ°á»›c 3: Cháº¡y Pipeline

**CÃ¡ch 1: Sá»­ dá»¥ng máº·c Ä‘á»‹nh (150-400 tokens/node)**

```bash
python main_pipeline.py document.pdf
```

**CÃ¡ch 2: TÃ¹y chá»‰nh kÃ­ch thÆ°á»›c node**

```bash
python main_pipeline.py document.pdf --min-tokens 200 --max-tokens 500
```

**CÃ¡ch 3: LÆ°u káº¿t quáº£ intermediate (debug)**

```bash
python main_pipeline.py document.pdf --save-intermediate
```

### BÆ°á»›c 4: Kiá»ƒm tra Káº¿t quáº£

```bash
# Xem file output JSON
ls -lh data/processed/

# Xem file text Ä‘Ã£ export
ls -lh data/exported/

# Xem ná»™i dung JSON
cat data/processed/document_lightrag.json | head -50

# Xem file text Ä‘á»ƒ review
cat data/exported/document_detailed.txt
```

## âš™ï¸ Options

| Option | Default | MÃ´ táº£ |
|--------|---------|-------|
| `--min-tokens` | 150 | Sá»‘ tokens tá»‘i thiá»ƒu má»—i node |
| `--max-tokens` | 400 | Sá»‘ tokens tá»‘i Ä‘a má»—i node |
| `--duplicate-threshold` | 0.85 | NgÆ°á»¡ng similarity Ä‘á»ƒ loáº¡i duplicate (0-1) |
| `--save-intermediate` | False | LÆ°u káº¿t quáº£ tá»«ng bÆ°á»›c vÃ o `temp_pipeline/` |
| `--list` | - | Hiá»ƒn thá»‹ danh sÃ¡ch PDF cÃ³ sáºµn |

## ğŸ“¤ Format Output

### 1. File JSON: `data/processed/<doc_id>_lightrag.json`

```json
{
  "doc_id": "document_name",
  "nodes": [
    {
      "id": "document_name_node_0000",
      "content": "Ná»™i dung cá»§a node...",
      "section": "TiÃªu Ä‘á» section",
      "metadata": {
        "doc_id": "document_name",
        "node_index": 0,
        "token_estimate": 250,
        "tags": ["Tim máº¡ch", "Cháº©n Ä‘oÃ¡n y khoa"],
        "domain": "Y há»c"
      }
    }
  ],
  "processing_info": {
    "source_file": "document_name.pdf",
    "processed_at": "2026-01-27T...",
    "pipeline_version": "1.1.0",
    "total_nodes": 15,
    "chunking_stats": {...},
    "audit_stats": {...},
    "tagging_stats": {
      "total_unique_tags": 8,
      "unique_tags": ["Tim máº¡ch", "Huyáº¿t Ã¡p", ...],
      "detected_domains": ["Y há»c"]
    }
  }
}
```

## ğŸ’» YÃªu cáº§u Há»‡ thá»‘ng

### Software

| Package | Version | Má»¥c Ä‘Ã­ch |
|---------|---------|----------|
| Python | 3.9+ | Runtime |
| marker-pdf | 0.2.0+ | PDF â†’ Markdown |
| PyTorch | 2.0+ | Deep learning models |

### Hardware

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| CPU | 4 cores | 8+ cores |
| RAM | 8 GB | 16 GB |
| GPU | KhÃ´ng báº¯t buá»™c | NVIDIA (4GB+ VRAM) |
| Disk | 5 GB | 10 GB (cho models) |

**LÆ°u Ã½:** Pipeline hiá»‡n cháº¡y á»Ÿ CPU mode (khÃ´ng cáº§n GPU)

### 2. File Text: `data/exported/`

Pipeline tá»± Ä‘á»™ng táº¡o 3 file text Ä‘á»ƒ review:

| File | MÃ´ táº£ | DÃ¹ng cho |
|------|-------|----------|
| `*_plain.txt` | Chá»‰ ná»™i dung text | Äá»c nhanh |
| `*_detailed.txt` | Ná»™i dung + metadata, tags, domain | Review chi tiáº¿t |
| `*_training.txt` | Format tá»‘i Æ°u cho AI training | Chuáº©n bá»‹ dataset |

## ğŸ¤– Auto-Tagging

Pipeline tá»± Ä‘á»™ng phÃ¢n loáº¡i ná»™i dung vÃ  gÃ¡n tags dá»±a trÃªn tá»« khÃ³a.

### CÃ¡c lÄ©nh vá»±c Ä‘Æ°á»£c há»— trá»£:

| LÄ©nh vá»±c | VÃ­ dá»¥ Tags |
|----------|-----------|
| **Y há»c** | Tim máº¡ch, Huyáº¿t Ã¡p, HÃ´ háº¥p, TiÃªu hÃ³a, Tháº§n kinh, Ung bÆ°á»›u, Cháº©n Ä‘oÃ¡n y khoa, Can thiá»‡p - Pháº«u thuáº­t, ... |
| **CÃ´ng nghá»‡ thÃ´ng tin** | Python, JavaScript, Database, Cloud Computing, AI, DevOps, Láº­p trÃ¬nh, Báº£o máº­t, ... |
| **Kinh táº¿ - TÃ i chÃ­nh** | NgÃ¢n hÃ ng, Chá»©ng khoÃ¡n, Äáº§u tÆ°, Marketing, Káº¿ toÃ¡n, Fintech, Khá»Ÿi nghiá»‡p, ... |
| **Luáº­t** | Luáº­t DÃ¢n sá»±, Luáº­t HÃ¬nh sá»±, Luáº­t ThÆ°Æ¡ng máº¡i, Luáº­t Lao Ä‘á»™ng, Sá»Ÿ há»¯u trÃ­ tuá»‡, ... |
| **GiÃ¡o dá»¥c** | GiÃ¡o dá»¥c Ä‘áº¡i há»c, E-Learning, NghiÃªn cá»©u há»c thuáº­t, PhÆ°Æ¡ng phÃ¡p giáº£ng dáº¡y, ... |
| **Ká»¹ thuáº­t** | CÆ¡ khÃ­, Äiá»‡n - Äiá»‡n tá»­, Tá»± Ä‘á»™ng hÃ³a, HÃ³a há»c, Váº­t lÃ½, ToÃ¡n há»c, ... |
| **NÃ´ng nghiá»‡p** | Trá»“ng trá»t, ChÄƒn nuÃ´i, Thá»§y sáº£n, NÃ´ng nghiá»‡p cÃ´ng nghá»‡ cao, ... |
| **XÃ¢y dá»±ng** | Kiáº¿n trÃºc, XÃ¢y dá»±ng dÃ¢n dá»¥ng, Báº¥t Ä‘á»™ng sáº£n, ... |
| **MÃ´i trÆ°á»ng** | Biáº¿n Ä‘á»•i khÃ­ háº­u, Xá»­ lÃ½ Ã´ nhiá»…m, NÄƒng lÆ°á»£ng tÃ¡i táº¡o, Báº£o tá»“n, ... |

### CÃ¡ch hoáº¡t Ä‘á»™ng:

1. Há»‡ thá»‘ng phÃ¢n tÃ­ch ná»™i dung node
2. TÃ¬m tá»« khÃ³a khá»›p vá»›i cÃ¡c lÄ©nh vá»±c
3. Tá»± Ä‘á»™ng gÃ¡n:
   - **Domain**: LÄ©nh vá»±c chÃ­nh (Y há»c, CNTT, ...)
   - **Tags**: CÃ¡c chá»§ Ä‘á» chi tiáº¿t

### VÃ­ dá»¥:

```json
{
  "content": "Tim máº¡ch lÃ  lÄ©nh vá»±c nghiÃªn cá»©u vá» tim vÃ  máº¡ch mÃ¡u...",
  "metadata": {
    "domain": "Y há»c",
    "tags": ["Tim máº¡ch", "Huyáº¿t Ã¡p", "Cháº©n Ä‘oÃ¡n y khoa"]
  }
}
```
## ğŸ”§ Pipeline Architecture

Pipeline gá»“m **7 bÆ°á»›c** xá»­ lÃ½ tuáº§n tá»±:

### 1. **Marker Conversion** (`marker.py`)
- Chuyá»ƒn Ä‘á»•i PDF â†’ Markdown sá»­ dá»¥ng deep learning
- Output: JSON vá»›i markdown content

### 2. **Initial Cleaning** (`pipeline/cleaning_v1.py`)
- Loáº¡i bá» header/footer láº·p láº¡i
- Normalize whitespace
- XÃ³a page artifacts (sá»‘ trang, dividers)
- Output: `cleaned_content`

### 3. **Vietnamese Cleanup** (`pipeline/final_cleaning.py`)
- Sá»­a lá»—i line-break trong tiáº¿ng Viá»‡t
- Sá»­a lá»—i OCR thÆ°á»ng gáº·p
- Normalize punctuation
- Output: `final_content`

### 4. **Semantic Chunking** (`pipeline/chunking.py`)
- Táº¡o semantic nodes (150-400 tokens)
- Split theo heading vÃ  paragraph
- KhÃ´ng bao giá» split cÃ¢u
- Output: `nodes[]`

### 5. **Audit & Deduplication** (`pipeline/audit_nodes.py`)
- Loáº¡i bá» duplicate/near-duplicate nodes
- Merge cÃ¡c node ngáº¯n liá»n ká»
- Validate cháº¥t lÆ°á»£ng node
- Output: Cleaned `nodes[]`

### 6. **Auto-Tagging** (`pipeline/auto_tagging.py`)
- Tá»± Ä‘á»™ng phÃ¡t hiá»‡n lÄ©nh vá»±c (domain)
- GÃ¡n tags dá»±a trÃªn ná»™i dung
- Há»— trá»£ 10+ lÄ©nh vá»±c (Y há»c, CNTT, Kinh táº¿, ...)
- Output: Tagged `nodes[]`

### 7. **Export Text Files** (`export_text.py`)
- Táº¡o file plain text Ä‘á»ƒ review
- Táº¡o file detailed vá»›i metadata
- Táº¡o file training format cho AI
- Output: 3 text files trong `data/exported/`