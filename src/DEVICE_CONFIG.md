# ğŸ¯ HÆ°á»›ng dáº«n cáº¥u hÃ¬nh Device: CPU vs GPU

## ğŸ“Œ TÃ³m táº¯t Nhanh

| Cháº¿ Ä‘á»™ | Lá»‡nh | Tá»‘c Ä‘á»™ | YÃªu cáº§u |
|--------|------|--------|---------|
| **CPU** (máº·c Ä‘á»‹nh) | `--device cpu` | Cháº­m (2-10x) | KhÃ´ng yÃªu cáº§u |
| **GPU** (nhanh) | `--device gpu` | Nhanh (2-10x) | GPU NVIDIA |

## ğŸ”§ Cháº¿ Ä‘á»™ CPU (Máº·c Ä‘á»‹nh - Cháº¡y Ä‘Æ°á»£c trÃªn má»i mÃ¡y)

### Khi nÃ o dÃ¹ng CPU?
- âœ… Láº§n Ä‘áº§u thá»­ nghiá»‡m
- âœ… MÃ¡y khÃ´ng cÃ³ GPU  
- âœ… GPU khÃ´ng Ä‘á»§ VRAM
- âœ… Xá»­ lÃ½ PDF nhá»
- âœ… Tiáº¿t kiá»‡m Ä‘iá»‡n nÄƒng

### CÃ¡ch cháº¡y (CPU)

**Máº·c Ä‘á»‹nh (tá»± Ä‘á»™ng chá»n CPU):**
```bash
source activate.sh
python main_pipeline.py document.pdf
```

**Chá»‰ Ä‘á»‹nh rÃµ rÃ ng (CPU):**
```bash
source activate.sh
python main_pipeline.py document.pdf --device cpu
```

**CPU + Custom Options:**
```bash
source activate.sh
python main_pipeline.py document.pdf --device cpu --min-tokens 200 --max-tokens 500
```

### ThÃ´ng tin CPU

Kiá»ƒm tra xem mÃ¬nh Ä‘ang dÃ¹ng CPU:
```bash
source activate.sh
python3 -c "import torch; print('Device:', 'CPU' if not torch.cuda.is_available() else 'GPU possible')"
```

### Notes CPU
- ğŸ¢ Cháº­m: Má»™t file PDF 14 trang => ~10-30 phÃºt (CPU)
- âœ… An toÃ n: KhÃ´ng phá»¥ thuá»™c GPU
- ğŸ’¾ RAM: Cáº§n 8GB+ RAM


## ğŸš€ Cháº¿ Ä‘á»™ GPU (Nhanh - YÃªu cáº§u NVIDIA GPU)

### Khi nÃ o dÃ¹ng GPU?
- âœ… CÃ³ GPU NVIDIA  
- âœ… GPU cÃ³ >= 4GB VRAM
- âœ… Cáº§n xá»­ lÃ½ nhanh
- âœ… Xá»­ lÃ½ hÃ ng loáº¡t PDF lá»›n
- âœ… Model cÃ³ >= 28GB VRAM

### YÃªu cáº§u GPU

1. **Hardware:**
   - GPU NVIDIA (GeForce RTX, A100, Tesla, ...)
   - VRAM >= 4GB (khuyáº¿n khÃ­ch 8GB+)

2. **Software:**
   - CUDA Toolkit 12.1+
   - cuDNN 8.9+
   - PyTorch vá»›i CUDA support âœ… (Ä‘Ã£ cÃ i sáºµn)

3. **Driver:**
   - NVIDIA Driver phiÃªn báº£n má»›i nháº¥t

### CÃ¡ch cháº¡y (GPU)

**Chá»‰ Ä‘á»‹nh cháº¿ Ä‘á»™ GPU:**
```bash
source activate.sh
python main_pipeline.py document.pdf --device gpu
```

**GPU + Custom Options:**
```bash
source activate.sh
python main_pipeline.py document.pdf --device gpu --min-tokens 200 --max-tokens 500
```

**Xá»­ lÃ½ hÃ ng loáº¡t (GPU):**
```bash
source activate.sh

# PDF 1
python main_pipeline.py document1.pdf --device gpu

# PDF 2
python main_pipeline.py document2.pdf --device gpu

# Xem danh sÃ¡ch
python main_pipeline.py --list
```

### Kiá»ƒm tra GPU Setup

#### 1ï¸âƒ£ Kiá»ƒm tra NVIDIA Driver
```bash
nvidia-smi
```

**Output mong Ä‘á»£i:**
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 550.XX  Driver Version: 550.XX      CUDA Version: 12.1         |
|-------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce RTX ...   Off  | 00:1F.0     Off |                  N/A |
|  0%   35C    P8    10W / 250W |   1234MiB /  8192MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```

#### 2ï¸âƒ£ Kiá»ƒm tra CUDA
```bash
source activate.sh
python3 -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'CUDA Version: {torch.version.cuda}')"
```

**Output mong Ä‘á»£i:**
```
CUDA Available: True
CUDA Version: 12.1
```

#### 3ï¸âƒ£ Kiá»ƒm tra GPU kháº£ dá»¥ng
```bash
source activate.sh
python3 -c "import torch; print(f'GPU Count: {torch.cuda.device_count()}'); print(f'GPU 0: {torch.cuda.get_device_name(0)}')"
```

**Output mong Ä‘á»£i:**
```
GPU Count: 1
GPU 0: NVIDIA GeForce RTX 3090
```

### Hiá»‡u suáº¥t GPU

| PDF Size | CPU | GPU | TÄƒng tá»‘c |
|----------|-----|-----|----------|
| 5 TB | 2 phÃºt | 12 giÃ¢y | ~10x |
| 140 trang | 30 phÃºt | 3 phÃºt | ~10x |
| 14 trang | 5 phÃºt | 30 giÃ¢y | ~10x |

### Notes GPU
- âš¡ Nhanh: Má»™t file PDF 14 trang => ~30 giÃ¢y (GPU)
- âœ… Tá»‘i Æ°u: Marker Ä‘Æ°á»£c thiáº¿t káº¿ cho GPU
- ğŸ’¾ VRAM: Cáº§n >= 4GB VRAM (khuyáº¿n khÃ­ch 8GB+)


## ğŸ”„ Chuyá»ƒn Ä‘á»•i giá»¯a CPU vÃ  GPU

### CÃ¡ch 1: DÃ¹ng `--device` flag (nÃªn dÃ¹ng)

**Cháº¡y CPU:**
```bash
python main_pipeline.py document.pdf --device cpu
```

**Cháº¡y GPU:**
```bash
python main_pipeline.py document.pdf --device gpu
```

### CÃ¡ch 2: Kiá»ƒm tra device hiá»‡n táº¡i

```bash
source activate.sh
python3 << 'EOF'
import torch
if torch.cuda.is_available():
    print(f"âœ… GPU Available: {torch.cuda.get_device_name(0)}")
    print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f}GB")
else:
    print("âŒ GPU Not Available (using CPU)")
EOF
```


## ğŸ› ï¸ Kháº¯c phá»¥c sá»± cá»‘

### âŒ "CUDA out of memory"
**Giáº£i phÃ¡p:**
- Giáº£m `--max-tokens` (tá»« 400 xuá»‘ng 300)
- Chuyá»ƒn sang CPU: `--device cpu`
- Upgrade GPU VRAM

```bash
# Thay vÃ¬ 400:
python main_pipeline.py document.pdf --device gpu --max-tokens 300
```

### âŒ GPU not available
**Giáº£i phÃ¡p:**
1. Kiá»ƒm tra nvidia-smi:
   ```bash
   nvidia-smi
   ```
2. Cáº­p nháº­t driver: https://www.nvidia.com/Download/index.aspx
3. DÃ¹ng CPU táº¡m: 
   ```bash
   python main_pipeline.py document.pdf --device cpu
   ```

### âŒ "torch.cuda.is_available() = False"
**Giáº£i phÃ¡p:**
- PyTorch khÃ´ng detect GPU
- DÃ¹ng CPU táº¡m thá»i
- Kiá»ƒm tra CUDA installation

```bash
# CÃ i láº¡i PyTorch vá»›i CUDA:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

### âŒ "CUDA version mismatch"
**Giáº£i phÃ¡p:**
```bash
# Kiá»ƒm tra CUDA version hiá»‡n táº¡i:
nvcc --version

# CÃ i Ä‘Ãºng version:
pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu121
```


## ğŸ“Š So sÃ¡nh CPU vs GPU - Chi tiáº¿t

### CPU Mode - Máº·c Ä‘á»‹nh

**Æ¯u Ä‘iá»ƒm:**
- âœ… KhÃ´ng yÃªu cáº§u GPU
- âœ… TÆ°Æ¡ng thÃ­ch vá»›i má»i mÃ¡y
- âœ… Dá»… cÃ i Ä‘áº·t
- âœ… Ãt yÃªu cáº§u dependencies
- âœ… á»”n Ä‘á»‹nh

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Cháº­m (10-30 phÃºt cho file 14 trang)
- âŒ LÃ£ng phÃ­ CPU resources
- âŒ TiÃªu tá»‘n Ä‘iá»‡n

**ThÃ­ch há»£p cho:**
- Laptop khÃ´ng GPU
- Desktop vá»›i CPU máº¡nh
- Thá»­ nghiá»‡m/test
- PDF nhá»

**VÃ­ dá»¥:**
```bash
# PDF 14 trang - CPU
python main_pipeline.py test_simple_2.pdf --device cpu
# => Khoáº£ng 5-10 phÃºt
```


### GPU Mode - Nhanh

**Æ¯u Ä‘iá»ƒm:**
- âœ… Nhanh 2-10x
- âœ… Tá»‘i Æ°u cho Marker
- âœ… Hiá»‡u quáº£ cho batch processing
- âœ… Giáº£i phÃ³ng CPU cho viá»‡c khÃ¡c

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ YÃªu cáº§u GPU NVIDIA
- âŒ YÃªu cáº§u cÃ i CUDA/cuDNN
- âŒ TiÃªu tá»‘n Ä‘iá»‡n (GPU)

**ThÃ­ch há»£p cho:**
- Desktop/Laptop vá»›i GPU NVIDIA
- Xá»­ lÃ½ hÃ ng loáº¡t PDF
- Production environment
- Thá»i gian pháº£i nhanh

**VÃ­ dá»¥:**
```bash
# PDF 14 trang - GPU  
python main_pipeline.py test_simple_2.pdf --device gpu
# => Khoáº£ng 30 giÃ¢y - 1 phÃºt
```


## ğŸ“ Quy trÃ¬nh chá»n Device

```
CÃ³ GPU NVIDIA?
â”œâ”€ CÃ³ & VRAM >= 4GB?
â”‚  â”œâ”€ CÃ³  â†’ DÃ¹ng GPU: --device gpu âš¡
â”‚  â””â”€ KhÃ´ng â†’ DÃ¹ng CPU: --device cpu ğŸ¢
â”‚
â””â”€ KhÃ´ng â†’ DÃ¹ng CPU: --device cpu ğŸ¢
```

## ğŸ“ Máº¹o & Best Practices

### Máº¹o 1: Cháº¡y test trÆ°á»›c
```bash
# Test trÃªn file nhá» trÆ°á»›c
python main_pipeline.py test_simple_2.pdf --device gpu

# Náº¿u ok, cháº¡y file lá»›n
python main_pipeline.py large_document.pdf --device gpu
```

### Máº¹o 2: Monitor GPU
```bash
# Terminal 1: Cháº¡y pipeline
python main_pipeline.py document.pdf --device gpu

# Terminal 2: Monitor GPU (trong lÃºc cháº¡y)
watch -n 1 nvidia-smi
```

### Máº¹o 3: Batch process
```bash
# Xá»­ lÃ½ hÃ ng loáº¡t file (GPU nhanh hÆ¡n)
for file in data/raw/*.pdf; do
    python main_pipeline.py "$(basename $file)" --device gpu
done
```

### Máº¹o 4: So sÃ¡nh tá»‘c Ä‘á»™
```bash
# Test CPU
time python main_pipeline.py test_simple_2.pdf --device cpu

# Test GPU
time python main_pipeline.py test_simple_2.pdf --device gpu
```

---

**Cáº§n giÃºp?** Xem [QUICKSTART.md](QUICKSTART.md) hoáº·c [README.md](../README.md)
